{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12216c67-765d-413d-b817-d4c63f9bd988",
   "metadata": {},
   "source": [
    "### Notebook to do ensemble-averaged analysis of MPDATA simulations.\n",
    "This will be generalized to all tracer advection schemes in another notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "00b334c6-0964-4b43-8e05-f1933ecadb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages \n",
    "import numpy as np\n",
    "import xgcm\n",
    "from xgcm import Grid\n",
    "import xarray as xr\n",
    "import xroms\n",
    "from datetime import datetime\n",
    "import time # for counting \n",
    "import glob\n",
    "from xhistogram.xarray import histogram\n",
    "import cmocean.cm as cmo\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import matplotlib.ticker as tick\n",
    "from matplotlib.dates import DateFormatter\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from xhistogram.xarray import histogram\n",
    "from datetime import timedelta\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #The chaotic option, used to suppress issues with cf_time with xroms \n",
    "\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from matplotlib import pyplot as plt, patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6a0ce459-499c-4fd1-94e3-a7ba0a46b800",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_roms(path):\n",
    "    ds1 = xroms.open_netcdf(path)\n",
    "    ds1, grid1 = xroms.roms_dataset(ds1)\n",
    "    return ds1, grid1\n",
    "\n",
    "paths = ['/d2/home/dylan/idealized_nummix/shelf_mpdata_uwind_zerop1_dt_30_across2x_50d_avg.nc',\n",
    "         '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_mpdata_uwind_zerop1_dt_30_across2x_50d_ensmb1_avg.nc',\n",
    "         '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_mpdata_uwind_zerop1_dt_30_across2x_50d_ensmb2_avg.nc',\n",
    "         '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_mpdata_uwind_zerop1_dt_30_across2x_50d_ensmb3_avg.nc',\n",
    "         '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_mpdata_uwind_zerop1_dt_30_across2x_50d_ensmb4_avg.nc',\n",
    "         '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_mpdata_uwind_zerop1_dt_30_across2x_50d_ensmb5_avg.nc',\n",
    "         '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_mpdata_uwind_zerop1_dt_30_across2x_50d_ensmb6_avg.nc',\n",
    "         '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_mpdata_uwind_zerop1_dt_30_across2x_50d_ensmb7_avg.nc',\n",
    "        ]\n",
    "\n",
    "def open_roms(path):\n",
    "    ds1 = xroms.open_netcdf(path)\n",
    "    ds1, grid1 = xroms.roms_dataset(ds1)\n",
    "    ds1 = ds1.isel(ocean_time = slice(0,721))\n",
    "    return ds1, grid1\n",
    "\n",
    "ds = []\n",
    "grid = []\n",
    "for i in range(len(paths)):\n",
    "    ds1, grid1 = open_roms(paths[i])\n",
    "    ds.append(ds1)\n",
    "    grid.append(grid1)\n",
    "    # print('iter complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9659fd0c-7e71-4a81-a0a5-09dfba462154",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixing_vint(ds,grid,xislice,etaslice):\n",
    "    \n",
    "    mnum = (ds.dye_03*ds.dV).isel(eta_rho = etaslice, xi_rho = xislice).sum(['s_rho','eta_rho','xi_rho'])\n",
    "    mnum.attrs = ''\n",
    "    mnum.name = 'mnum'\n",
    "    \n",
    "    Akr = ds.AKr\n",
    "    AKr_rho = grid.interp(Akr, 'Z', boundary = 'extend')\n",
    "    mphy = (AKr_rho*ds.dV).isel(eta_rho = etaslice, xi_rho = xislice).sum(['s_rho','eta_rho','xi_rho'])\n",
    "    mphy.attrs = ''\n",
    "    mphy.name = 'mphy'\n",
    "    \n",
    "    mt = ds.dye_03+AKr_rho\n",
    "    mtot = (mt*ds.dV).isel(eta_rho = etaslice, xi_rho = xislice).sum(['s_rho','eta_rho','xi_rho'])\n",
    "    mtot.attrs = ''\n",
    "    mtot.name = 'mtot'\n",
    "    \n",
    "    ds_mix = xr.merge([mnum, mphy, mtot])\n",
    "    return ds_mix\n",
    "\n",
    "def mixing_pervol(ds, grid, etaslice, xislice):\n",
    "    '''\n",
    "Computes volume-integrated physical and numerical mixing for ROMS model output.\n",
    "See Schlichting et al. (2023) JAMES for more information.\n",
    "    '''\n",
    "    mnum = ds.dye_03.isel(eta_rho = etaslice, xi_rho = xislice) #Numerical salt mixing\n",
    "    AKr = grid.interp(ds.AKr, 'Z') #Destruction of salt variance\n",
    "\n",
    "    mphy = AKr.isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    dV = ds.dV.isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    V = dV.sum(['eta_rho','xi_rho','s_rho'])\n",
    "    \n",
    "    #Volume integrate, then name for concat\n",
    "    mnum_int = (mnum*dV).sum(['eta_rho', 'xi_rho', 's_rho'])\n",
    "    mnum_int.attrs = [] # Remove grid so we can save to netcdf \n",
    "    mphy_int = (mphy*dV).sum(['eta_rho', 'xi_rho', 's_rho'])\n",
    "    mphy_int.attrs = []\n",
    "    mtot = mnum+mphy \n",
    "    mtot_int = (mtot*dV).sum(['eta_rho','xi_rho','s_rho'])\n",
    "    mtot_int.attrs = ''\n",
    "\n",
    "    mnum_pervol = (mnum_int/V)\n",
    "    mnum_pervol.name = 'mnum'\n",
    "    mphy_pervol = (mphy_int/V)\n",
    "    mphy_pervol.name = 'mphy'\n",
    "    mtot_pervol = (mtot_int/V)\n",
    "    mtot_pervol.name = 'mtot'\n",
    "    \n",
    "    ds_mix = xr.merge([mnum_pervol, mphy_pervol, mtot_pervol])\n",
    "    return ds_mix\n",
    "\n",
    "def mixing_vint_top1m(ds,grid,xislice,etaslice):\n",
    "    \n",
    "    mnum = (ds.dye_03*ds.dV).where(ds.z_rho>-1).isel(eta_rho = etaslice, xi_rho = xislice).sum(['s_rho','eta_rho','xi_rho'])\n",
    "    mnum.attrs = ''\n",
    "    mnum.name = 'mnum'\n",
    "    \n",
    "    Akr = ds.AKr\n",
    "    AKr_rho = grid.interp(Akr, 'Z', boundary = 'extend')\n",
    "    mphy = (AKr_rho*ds.dV).where(ds.z_rho>-1).isel(eta_rho = etaslice, xi_rho = xislice).sum(['s_rho','eta_rho','xi_rho'])\n",
    "    mphy.attrs = ''\n",
    "    mphy.name = 'mphy'\n",
    "    \n",
    "    mt = ds.dye_03+AKr_rho\n",
    "    mtot = (mt*ds.dV).where(ds.z_rho>-1).isel(eta_rho = etaslice, xi_rho = xislice).sum(['s_rho','eta_rho','xi_rho'])\n",
    "    mtot.attrs = ''\n",
    "    mtot.name = 'mtot'\n",
    "    \n",
    "    ds_mix_1m = xr.merge([mnum, mphy, mtot])\n",
    "    return ds_mix_1m\n",
    "\n",
    "def energy_vint(ds,grid,etaslice,xislice):\n",
    "    '''\n",
    "Modifies volume-integrated eddy, mean, and total kinetic energy modified from Hetland (2017) JPO.\n",
    "Notes:\n",
    "------\n",
    "EKE = 1/2(uprime^2 + v^2). \n",
    "MKE = 1/2(ubar^2+vbar^2)\n",
    "TKE = 1/2(u^2+v^2)\n",
    "u = ubar+uprime, ubar = 1/L int_0^L u dx, i.e., alongshore mean\n",
    "v = vbar+vprime\n",
    "Velocities interpolated to their respective rho points\n",
    "    '''\n",
    "    u = xroms.to_rho(ds.u, grid)\n",
    "    urho = u.isel(eta_rho = etaslice, xi_rho = xislice) \n",
    "    v = xroms.to_rho(ds.v, grid)\n",
    "    vrho = v.isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    \n",
    "    ubar = urho.mean('xi_rho')\n",
    "    uprime = urho-ubar\n",
    "    \n",
    "    vbar = vrho.mean('xi_rho')\n",
    "    vprime = vrho-vbar\n",
    "    \n",
    "    dV = ds.dV.isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    #Mean kinetic energy\n",
    "    mke = 0.5*(ubar**2+vbar**2)\n",
    "    mke_int = (mke*dV).sum(['eta_rho', 'xi_rho', 's_rho'])\n",
    "    mke_initial = (mke*dV).sum(['eta_rho', 'xi_rho', 's_rho'])[0] # Initial value for normalization\n",
    "    mke_int.attrs = ''\n",
    "    mke_int.name = 'mke'\n",
    "    mke_initial.attrs = ''\n",
    "    mke_initial.name = 'mke_initial'\n",
    "\n",
    "    #Eddy kinetic energy\n",
    "    eke = 0.5*(uprime**2 + vprime**2)\n",
    "    eke_int = (eke*dV).sum(['eta_rho', 'xi_rho', 's_rho'])\n",
    "    eke_int.attrs = ''\n",
    "    eke_int.name = 'eke'\n",
    "\n",
    "    #Total kinetic energy \n",
    "    tke = 0.5*(urho**2+vrho**2)\n",
    "    tke_int = (tke*dV).sum(['eta_rho', 'xi_rho', 's_rho'])\n",
    "    tke_int.attrs = ''\n",
    "    tke_int.name = 'tke'     \n",
    "    \n",
    "    ds_energy = xr.merge([eke_int, mke_int, tke_int])\n",
    "    return ds_energy\n",
    "\n",
    "def sprime2_whole(ds, grid, xislice, etaslice):\n",
    "    ''' \n",
    "Returns volume-averaged salinity variance. \n",
    "Inputs:\n",
    "----\n",
    "ds: DataArray\n",
    "salt: DataArray\n",
    "Outputs:\n",
    "----\n",
    "svar: total salinity variance\n",
    "    '''\n",
    "    salt = ds.salt.isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    dV = ds.dV.isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    V = dV.sum(['s_rho', 'xi_rho', 'eta_rho'])\n",
    "    \n",
    "    sbar = (1/V)*((salt*dV).sum(['s_rho', 'xi_rho', 'eta_rho']))\n",
    "    sp_tot = (1/V)*((((salt-sbar)**2)*dV).sum(['s_rho', 'xi_rho', 'eta_rho']))\n",
    "    \n",
    "    return sp_tot\n",
    "\n",
    "\n",
    "def sprime2_top1m(ds, grid, xislice, etaslice):\n",
    "    ''' \n",
    "Returns volume-averaged salinity variance. \n",
    "Inputs:\n",
    "----\n",
    "ds: DataArray\n",
    "salt: DataArray\n",
    "Outputs:\n",
    "----\n",
    "svar: total salinity variance\n",
    "    '''\n",
    "    salt = ds.salt.where(ds.z_rho>-1).isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    dV = ds.dV.where(ds.z_rho>-1).isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    V = dV.sum(['s_rho', 'xi_rho', 'eta_rho'])\n",
    "    \n",
    "    sbar = (1/V)*((salt*dV).sum(['s_rho', 'xi_rho', 'eta_rho']))\n",
    "    sp_1m = (1/V)*((((salt-sbar)**2)*dV).sum(['s_rho', 'xi_rho', 'eta_rho']))\n",
    "    \n",
    "    return sp_1m\n",
    "\n",
    "def sprime2_whole(ds, grid, xislice, etaslice):\n",
    "    ''' \n",
    "Returns the volume-averaged terms for the decomposition of salinity variance: \n",
    "total, vertical, and horizontal variance. See Li et al. (2018) JPO for details.\n",
    "Inputs:\n",
    "----\n",
    "ds: DataArray\n",
    "salt: DataArray\n",
    "Outputs:\n",
    "----\n",
    "svar: total salinity variance\n",
    "svert: vertical salinity variance\n",
    "shorz: horizontal salinity variance\n",
    "    '''\n",
    "    salt = ds.salt.isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    dV = ds.dV.isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    V = dV.sum(['s_rho', 'xi_rho', 'eta_rho'])\n",
    "    \n",
    "    sbar = (1/V)*((salt*dV).sum(['s_rho', 'xi_rho', 'eta_rho']))\n",
    "    sp_tot = (1/V)*((((salt-sbar)**2)*dV).sum(['s_rho', 'xi_rho', 'eta_rho']))\n",
    "    \n",
    "    # Now compute the local vertical salinity variance\n",
    "    dz = ds.dz.isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    Z = dz.sum(['s_rho'])\n",
    "    sbar_z = (1/Z)*((salt*dz).sum(['s_rho']))\n",
    "    sp_vert = (1/V)*((((salt-sbar_z)**2)*dV).sum(['s_rho', 'xi_rho', 'eta_rho']))\n",
    "    \n",
    "    sp_horz = (sp_tot-sp_vert)\n",
    "    \n",
    "    sp_tot.attrs = ''\n",
    "    sp_tot.name = 'svar_tot'\n",
    "    sp_vert.attrs = ''\n",
    "    sp_vert.name = 'svar_vert'\n",
    "    sp_horz.attrs = ''\n",
    "    sp_horz.name = 'svar_horz'\n",
    "    \n",
    "    svar_da = xr.merge([sp_tot, sp_vert, sp_horz])\n",
    "    \n",
    "    return svar_da\n",
    "\n",
    "def rho_linear_eos(ds):\n",
    "    '''\n",
    "Calculate density based on linear equation of state described in Hetland (2017)\n",
    "    '''\n",
    "    rho = 1027*((1+7.6*(10**-4*(ds.salt-35)))-(1.7*10**-4*(ds.temp-25)))\n",
    "    return rho\n",
    "\n",
    "def calc_ape(ds, etaslice, xislice):\n",
    "    '''\n",
    "Calculate APE from lateral density gradients and SSH. See Eqs. B6 and B7\n",
    "of Hetland (2017)\n",
    "Inputs: \n",
    "-------\n",
    "ds - xarray dataset\n",
    "etaslice - across-shore slice (i.e. slice(1,100)) for init. stratified region. \n",
    "xislice - alongshore slice (i.e., slice(1,-1)) to remove periodic BCs\n",
    "\n",
    "Outputs:\n",
    "--------\n",
    "ape: xarray dataarray with energy stored in lateral density gradients\n",
    "    '''\n",
    "    rho0 = 1025 #background density determined from input file\n",
    "    rho = rho_linear_eos(ds)\n",
    "    \n",
    "    g = 9.81 \n",
    "    b = (g*(rho0-rho))*(1/rho0) \n",
    "    \n",
    "    rho_temp = (1027*(1-(1.7*10**-4*(ds.temp[0]-25)))).values #Temperature based density @ first time\n",
    "    rho_init = rho[0].values #Initial density \n",
    "    bref = (g*(1025-(rho_temp)))*(1/1025) #Reference buoyancy @ first time. Function of x,y,z\n",
    "\n",
    "    bp = b-bref\n",
    "    \n",
    "    #Lateral density gradient APE\n",
    "    ape_r = -((1025*bp*ds.z_rho*ds.dV).isel(eta_rho = etaslice, xi_rho = xislice).sum(['s_rho', 'eta_rho', 'xi_rho']))\n",
    "    ape_r.attrs = ''\n",
    "    ape_r.name = 'ape_r'\n",
    "    \n",
    "    return ape_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "279b51ed-2721-479c-bb67-39c492492a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the functions\n",
    "# -----------------\n",
    "xislice = slice(1,-1)\n",
    "etaslice = slice(1,193) \n",
    "# etaslice = slice(1,100)\n",
    "\n",
    "# dsm = []\n",
    "# for i in range(len(paths)):\n",
    "#     ds_mix = mixing_vint(ds[i],grid[i],xislice,etaslice)\n",
    "#     dsm.append(ds_mix)\n",
    "\n",
    "# dsm = []\n",
    "# for i in range(len(paths)):\n",
    "#     ds_mix = mixing_pervol(ds[i],grid[i],xislice,etaslice)\n",
    "#     dsm.append(ds_mix)\n",
    "    \n",
    "# dsm_1m = []\n",
    "# for i in range(len(paths)):\n",
    "#     ds_mix_1m = mixing_vint_top1m(ds[i],grid[i],xislice,etaslice)\n",
    "#     dsm_1m.append(ds_mix_1m)\n",
    "    \n",
    "dse = []\n",
    "for i in range(len(paths)):\n",
    "    ds_energy = energy_vint(ds[i],grid[i],etaslice,xislice)\n",
    "    dse.append(ds_energy)\n",
    "\n",
    "# svar = []\n",
    "# for i in range(len(paths)):\n",
    "#     svar_da = sprime2_whole(ds[i], grid[i], xislice, etaslice)\n",
    "#     svar.append(svar_da)\n",
    "    \n",
    "# svar = []\n",
    "# for i in range(len(paths)):\n",
    "#     sp_tot = sprime2_whole(ds[i], grid[i], xislice, etaslice)\n",
    "#     svar.append(sp_tot)\n",
    "\n",
    "# svar = []\n",
    "# for i in range(len(paths)):\n",
    "#     sp_tot = sprime2_whole(ds[i], grid[i], xislice, etaslice)\n",
    "#     svar.append(sp_tot)\n",
    "    \n",
    "# svar_1m = []\n",
    "# for i in range(len(paths)):\n",
    "#     sp_1m = sprime2_top1m(ds[i], grid[i], xislice, etaslice)\n",
    "#     svar_1m.append(sp_1m)\n",
    "\n",
    "# ds_ape = []\n",
    "# for i in range(len(paths)):\n",
    "#     start_time = time.time()   \n",
    "#     ape = calc_ape(ds[i], etaslice, xislice)\n",
    "#     ds_ape.append(ape)\n",
    "#     print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f86fe729-ffee-48af-8045-f049bfdeffc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0 # Start at zero\n",
    "# n = 5\n",
    "\n",
    "# for i in range(len(paths)):\n",
    "#     # svar[i].attrs = ''\n",
    "#     # svar[i].name = 'svar'\n",
    "#     p = 'svar_vavg_whole_mpdata_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     svar[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     svar_1m[i].attrs = ''\n",
    "#     svar_1m[i].name = 'svar'\n",
    "#     p = 'svar_vavg_top1m_mpdata_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     svar_1m[i].to_netcdf(p, mode = 'w')\n",
    "\n",
    "for i in range(len(paths)):\n",
    "    p = 'outputs/ene_vint_whole_mpdata_'+'ensemble_'+str(i+n)+'.nc'\n",
    "    dse[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     p = 'mix_vint_whole_mpdata_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     dsm[i].to_netcdf(p, mode = 'w')\n",
    "\n",
    "# for i in range(len(paths)):\n",
    "#     p = 'mix_pervol_whole_mpdata_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     dsm[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     p = 'mix_vint_top1m_mpdata_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     dsm_1m[i].to_netcdf(p, mode = 'w')\n",
    "\n",
    "# for i in range(len(paths)):\n",
    "#     start_time = time.time()   \n",
    "#     p = 'outputs/ape_vint_whole_mpdata_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     ds_ape[i].to_netcdf(p, mode = 'w')\n",
    "#     print(time.time() - start_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd496f6-66bc-4754-b716-d6d54586d88f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "copano",
   "language": "python",
   "name": "copano"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
