{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "76e6c423-eeb9-4986-b4e7-a934ea40d75b",
   "metadata": {},
   "source": [
    "### Notebook to calculate various volume-integrated quantities over the short domain for the 2X across-shore shelf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e670c7cd-12ff-43b3-8e69-d5c5b9797d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Packages \n",
    "import numpy as np\n",
    "import xgcm\n",
    "from xgcm import Grid\n",
    "import xarray as xr\n",
    "import xroms\n",
    "from datetime import datetime\n",
    "\n",
    "import glob\n",
    "from xhistogram.xarray import histogram\n",
    "import cmocean.cm as cmo\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import colors\n",
    "import matplotlib.ticker as tick\n",
    "from matplotlib.dates import DateFormatter\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.ticker import AutoMinorLocator\n",
    "from xhistogram.xarray import histogram\n",
    "from datetime import timedelta\n",
    "import time\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\") #The chaotic option, used to suppress issues with cf_time with xroms \n",
    "\n",
    "from matplotlib.ticker import (MultipleLocator, AutoMinorLocator)\n",
    "from matplotlib import pyplot as plt, patches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a4f1914-6598-440d-b935-c2e0c05a43d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def open_roms(path):\n",
    "    ds1 = xroms.open_netcdf(path)\n",
    "    ds1, grid1 = xroms.roms_dataset(ds1)\n",
    "    return ds1, grid1\n",
    "\n",
    "# HSIMT\n",
    "# paths = ['/d2/home/dylan/idealized_nummix/shelf_hsimt_uwind_zerop1_dt_30_across2x_50d_avg.nc',\n",
    "#          '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_hsimt_uwind_zerop1_dt_30_across2x_50d_ensmb1_avg.nc',\n",
    "#          '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_hsimt_uwind_zerop1_dt_30_across2x_50d_ensmb2_avg.nc',\n",
    "#          '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_hsimt_uwind_zerop1_dt_30_across2x_50d_ensmb3_avg.nc',\n",
    "#          '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_hsimt_uwind_zerop1_dt_30_across2x_50d_ensmb4_avg.nc',\n",
    "#          '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_hsimt_uwind_zerop1_dt_30_across2x_50d_ensmb5_avg.nc',\n",
    "#          '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_hsimt_uwind_zerop1_dt_30_across2x_50d_ensmb6_avg.nc',\n",
    "#          '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_hsimt_uwind_zerop1_dt_30_across2x_50d_ensmb7_avg.nc',\n",
    "#         ]\n",
    "# MPDATA\n",
    "# paths = ['/d2/home/dylan/idealized_nummix/shelf_mpdata_uwind_zerop1_dt_30_across2x_50d_avg.nc',\n",
    "#          '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_mpdata_uwind_zerop1_dt_30_across2x_50d_ensmb1_avg.nc',\n",
    "#          '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_mpdata_uwind_zerop1_dt_30_across2x_50d_ensmb2_avg.nc',\n",
    "#          '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_mpdata_uwind_zerop1_dt_30_across2x_50d_ensmb3_avg.nc',\n",
    "#          '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_mpdata_uwind_zerop1_dt_30_across2x_50d_ensmb4_avg.nc',\n",
    "#          '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_mpdata_uwind_zerop1_dt_30_across2x_50d_ensmb5_avg.nc',\n",
    "#          '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_mpdata_uwind_zerop1_dt_30_across2x_50d_ensmb6_avg.nc',\n",
    "#          '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_mpdata_uwind_zerop1_dt_30_across2x_50d_ensmb7_avg.nc',\n",
    "#         ]\n",
    "# U3HC4\n",
    "paths = ['/d2/home/dylan/idealized_nummix/shelf_u3hc4_uwind_zerop1_dt_30_across2x_50d_avg.nc',\n",
    "         '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_u3hc4_uwind_zerop1_dt_30_across2x_50d_ensmb1_avg.nc',\n",
    "         '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_u3hc4_uwind_zerop1_dt_30_across2x_50d_ensmb2_avg.nc',\n",
    "         '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_u3hc4_uwind_zerop1_dt_30_across2x_50d_ensmb3_avg.nc',\n",
    "         '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_u3hc4_uwind_zerop1_dt_30_across2x_50d_ensmb4_avg.nc',\n",
    "         '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_u3hc4_uwind_zerop1_dt_30_across2x_50d_ensmb5_avg.nc',\n",
    "         '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_u3hc4_uwind_zerop1_dt_30_across2x_50d_ensmb6_avg.nc',\n",
    "         '/d1/shared/shelfstrat_wind/tadv_ensembles/shelf_u3hc4_uwind_zerop1_dt_30_across2x_50d_ensmb7_avg.nc',\n",
    "        ]\n",
    "\n",
    "def open_roms(path):\n",
    "    ds1 = xroms.open_netcdf(path)\n",
    "    ds1, grid1 = xroms.roms_dataset(ds1)\n",
    "    ds1 = ds1.isel(ocean_time = slice(0,723))\n",
    "    return ds1, grid1\n",
    "\n",
    "ds = []\n",
    "grid = []\n",
    "for i in range(len(paths)):\n",
    "    ds1, grid1 = open_roms(paths[i])\n",
    "    ds.append(ds1)\n",
    "    grid.append(grid1)\n",
    "    # print('iter complete')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cb53d4c-0dd7-4a71-a7ea-3eafaab8ab34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0001-01-31 02:30:00\n",
      "723\n",
      "0001-01-30 23:30:00\n",
      "720\n",
      "0001-01-30 23:30:00\n",
      "720\n",
      "0001-01-30 23:30:00\n",
      "720\n",
      "0001-01-30 23:30:00\n",
      "720\n",
      "0001-01-30 23:30:00\n",
      "720\n",
      "0001-01-30 23:30:00\n",
      "720\n",
      "0001-01-30 23:30:00\n",
      "720\n"
     ]
    }
   ],
   "source": [
    "t = -1\n",
    "for i in range(len(paths)):\n",
    "    print(ds[i].ocean_time[t].values)\n",
    "    print(len(ds[i].ocean_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea843ffb-132e-480c-bf4d-fe4e71f049d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mixing_vint(ds,grid,xislice,etaslice):\n",
    "    \n",
    "    mnum = (ds.dye_03*ds.dV).isel(eta_rho = etaslice, xi_rho = xislice).sum(['s_rho','eta_rho','xi_rho'])\n",
    "    mnum.attrs = ''\n",
    "    mnum.name = 'mnum'\n",
    "    \n",
    "    Akr = ds.AKr\n",
    "    AKr_rho = grid.interp(Akr, 'Z', boundary = 'extend')\n",
    "    mphy = (AKr_rho*ds.dV).isel(eta_rho = etaslice, xi_rho = xislice).sum(['s_rho','eta_rho','xi_rho'])\n",
    "    mphy.attrs = ''\n",
    "    mphy.name = 'mphy'\n",
    "    \n",
    "    mt = ds.dye_03+AKr_rho\n",
    "    mtot = (mt*ds.dV).isel(eta_rho = etaslice, xi_rho = xislice).sum(['s_rho','eta_rho','xi_rho'])\n",
    "    mtot.attrs = ''\n",
    "    mtot.name = 'mtot'\n",
    "    \n",
    "    ds_mix = xr.merge([mnum, mphy, mtot])\n",
    "    return ds_mix\n",
    "\n",
    "def mixing_vint_top1m(ds,grid,xislice,etaslice):\n",
    "    \n",
    "    mnum = (ds.dye_03*ds.dV).where(ds.z_rho>-1).isel(eta_rho = etaslice, xi_rho = xislice).sum(['s_rho','eta_rho','xi_rho'])\n",
    "    mnum.attrs = ''\n",
    "    mnum.name = 'mnum'\n",
    "    \n",
    "    Akr = ds.AKr\n",
    "    AKr_rho = grid.interp(Akr, 'Z', boundary = 'extend')\n",
    "    mphy = (AKr_rho*ds.dV).where(ds.z_rho>-1).isel(eta_rho = etaslice, xi_rho = xislice).sum(['s_rho','eta_rho','xi_rho'])\n",
    "    mphy.attrs = ''\n",
    "    mphy.name = 'mphy'\n",
    "    \n",
    "    mt = ds.dye_03+AKr_rho\n",
    "    mtot = (mt*ds.dV).where(ds.z_rho>-1).isel(eta_rho = etaslice, xi_rho = xislice).sum(['s_rho','eta_rho','xi_rho'])\n",
    "    mtot.attrs = ''\n",
    "    mtot.name = 'mtot'\n",
    "    \n",
    "    ds_mix_1m = xr.merge([mnum, mphy, mtot])\n",
    "    return ds_mix_1m\n",
    "\n",
    "def energy_vint(ds,grid,xislice,etaslice):\n",
    "    '''\n",
    "Calculates volume-integrated eddy, mean, and total kinetic energy based on \n",
    "Hetland (2017) JPO.\n",
    "Notes:\n",
    "------\n",
    "EKE = 1/2(uprime^2 + v^2). \n",
    "MKE = 1/2(ubar^2)\n",
    "TKE = 1/2(u^2+v^2)\n",
    "u = ubar+uprime, ubar = 1/L int_0^L u dx, i.e., alongshore mean\n",
    "vbar = 0 by design.\n",
    "Velocities interpolated to their respective rho points\n",
    "    '''\n",
    "    u = xroms.to_rho(ds.u, grid)\n",
    "    u = u.isel(eta_rho = etaslice, xi_rho = xislice) \n",
    "    v = xroms.to_rho(ds.v, grid)\n",
    "    v = v.isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    ubar = u.mean('xi_rho')\n",
    "    uprime = u-ubar\n",
    "    vprime = v\n",
    "    \n",
    "    #Eddy kinetic energy\n",
    "    eke = 0.5*(uprime**2 + vprime**2)\n",
    "    dV = ds.dV.isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    eke_int = (eke*dV).sum(['eta_rho', 'xi_rho', 's_rho'])\n",
    "    eke_int.attrs = ''\n",
    "    eke_int.name = 'eke'\n",
    "    \n",
    "    #Mean kinetic energy\n",
    "    mke = 0.5*ubar**2\n",
    "    mke_int = (mke*dV).sum(['eta_rho', 'xi_rho', 's_rho'])\n",
    "    mke_int.attrs = ''\n",
    "    mke_int.name = 'mke'\n",
    "    \n",
    "    #Total kinetic energy \n",
    "    tke = 0.5*(u**2+v**2)\n",
    "    tke_int = (tke*dV).sum(['eta_rho', 'xi_rho', 's_rho'])\n",
    "    tke_int.attrs = ''\n",
    "    tke_int.name = 'tke'\n",
    "    \n",
    "    ds_energy = xr.merge([eke_int, mke_int, tke_int])\n",
    "    return ds_energy\n",
    "\n",
    "def sprime2_whole(ds, grid, xislice, etaslice):\n",
    "    ''' \n",
    "Returns volume-averaged salinity variance. \n",
    "Inputs:\n",
    "----\n",
    "ds: DataArray\n",
    "salt: DataArray\n",
    "Outputs:\n",
    "----\n",
    "svar: total salinity variance\n",
    "    '''\n",
    "    salt = ds.salt.isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    dV = ds.dV.isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    V = dV.sum(['s_rho', 'xi_rho', 'eta_rho'])\n",
    "    \n",
    "    sbar = (1/V)*((salt*dV).sum(['s_rho', 'xi_rho', 'eta_rho']))\n",
    "    sp_tot = (1/V)*((((salt-sbar)**2)*dV).sum(['s_rho', 'xi_rho', 'eta_rho']))\n",
    "    \n",
    "    return sp_tot\n",
    "\n",
    "\n",
    "def sprime2_top1m(ds, grid, xislice, etaslice):\n",
    "    ''' \n",
    "Returns volume-averaged salinity variance. \n",
    "Inputs:\n",
    "----\n",
    "ds: DataArray\n",
    "salt: DataArray\n",
    "Outputs:\n",
    "----\n",
    "svar: total salinity variance\n",
    "    '''\n",
    "    salt = ds.salt.where(ds.z_rho>-1).isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    dV = ds.dV.where(ds.z_rho>-1).isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    V = dV.sum(['s_rho', 'xi_rho', 'eta_rho'])\n",
    "    \n",
    "    sbar = (1/V)*((salt*dV).sum(['s_rho', 'xi_rho', 'eta_rho']))\n",
    "    sp_1m = (1/V)*((((salt-sbar)**2)*dV).sum(['s_rho', 'xi_rho', 'eta_rho']))\n",
    "    \n",
    "    return sp_1m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7c8f4ae-c94f-4f96-9b62-39e4c976a522",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the functions\n",
    "# -----------------\n",
    "xislice = slice(1,-1)\n",
    "etaslice = slice(1,193) \n",
    "\n",
    "# dsm = []\n",
    "# for i in range(len(paths)):\n",
    "#     ds_mix = mixing_vint(ds[i],grid[i],xislice,etaslice)\n",
    "#     dsm.append(ds_mix)\n",
    "    \n",
    "# dsm_1m = []\n",
    "# for i in range(len(paths)):\n",
    "#     ds_mix_1m = mixing_vint_top1m(ds[i],grid[i],xislice,etaslice)\n",
    "#     dsm_1m.append(ds_mix_1m)\n",
    "    \n",
    "# dse = []\n",
    "# for i in range(len(paths)):\n",
    "#     ds_energy = energy_vint(ds[i],grid[i],xislice,etaslice)\n",
    "#     dse.append(ds_energy)\n",
    "    \n",
    "# svar = []\n",
    "# for i in range(len(paths)):\n",
    "#     sp_tot = sprime2_whole(ds[i], grid[i], xislice, etaslice)\n",
    "#     svar.append(sp_tot)\n",
    "    \n",
    "# svar_1m = []\n",
    "# for i in range(len(paths)):\n",
    "#     sp_1m = sprime2_top1m(ds[i], grid[i], xislice, etaslice)\n",
    "#     svar_1m.append(sp_1m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3feedec0-651f-4ea4-8ffd-fa24c24de77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sprime2_whole(ds, grid, xislice, etaslice):\n",
    "    ''' \n",
    "Returns the volume-averaged terms for the decomposition of salinity variance: \n",
    "total, vertical, and horizontal variance. See Li et al. (2018) JPO for details.\n",
    "Inputs:\n",
    "----\n",
    "ds: DataArray\n",
    "salt: DataArray\n",
    "Outputs:\n",
    "----\n",
    "svar: total salinity variance\n",
    "svert: vertical salinity variance\n",
    "shorz: horizontal salinity variance\n",
    "    '''\n",
    "    salt = ds.salt.isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    dV = ds.dV.isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    V = dV.sum(['s_rho', 'xi_rho', 'eta_rho'])\n",
    "    \n",
    "    sbar = (1/V)*((salt*dV).sum(['s_rho', 'xi_rho', 'eta_rho']))\n",
    "    sp_tot = (1/V)*((((salt-sbar)**2)*dV).sum(['s_rho', 'xi_rho', 'eta_rho']))\n",
    "    \n",
    "    # Now compute the local vertical salinity variance\n",
    "    dz = ds.dz.isel(eta_rho = etaslice, xi_rho = xislice)\n",
    "    Z = dz.sum(['s_rho'])\n",
    "    sbar_z = (1/Z)*((salt*dz).sum(['s_rho']))\n",
    "    sp_vert = (1/V)*((((salt-sbar_z)**2)*dV).sum(['s_rho', 'xi_rho', 'eta_rho']))\n",
    "    \n",
    "    sp_horz = (sp_tot-sp_vert)\n",
    "    \n",
    "    sp_tot.attrs = ''\n",
    "    sp_tot.name = 'svar_tot'\n",
    "    sp_vert.attrs = ''\n",
    "    sp_vert.name = 'svar_vert'\n",
    "    sp_horz.attrs = ''\n",
    "    sp_horz.name = 'svar_horz'\n",
    "    \n",
    "    svar_da = xr.merge([sp_tot, sp_vert, sp_horz])\n",
    "    \n",
    "    return svar_da\n",
    "\n",
    "svar = []\n",
    "for i in range(len(paths)):\n",
    "    svar_da = sprime2_whole(ds[i], grid[i], xislice, etaslice)\n",
    "    svar.append(svar_da)\n",
    "    \n",
    "# svar = []\n",
    "# for i in range(len(paths)):\n",
    "#     sp_tot = sprime2_whole(ds[i], grid[i], xislice, etaslice)\n",
    "#     svar.append(sp_tot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51291b91-17b0-46fe-8b78-0461794865cf",
   "metadata": {},
   "source": [
    "### Run the functions starting from the nth ensemble compared to a complete list of paths (e.g., 0-n)\n",
    "This can be easily adjusted if you want to rerun the calcs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aec7314f-8cf0-46cc-9dcd-c67dddfa009b",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 0 # Start at th\n",
    "# n = 5 # Start at the fifth ensemble\n",
    "# MPDATA\n",
    "# for i in range(len(paths)):\n",
    "#     # svar[i].attrs = ''\n",
    "#     # svar[i].name = 'svar'\n",
    "#     p = 'svar_vavg_decomp_mpdata_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     svar[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     svar_1m[i].attrs = ''\n",
    "#     svar_1m[i].name = 'svar'\n",
    "#     p = 'svar_vavg_top1m_mpdata_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     svar_1m[i].to_netcdf(p, mode = 'w')\n",
    "\n",
    "# for i in range(len(paths)):\n",
    "#     p = 'ene_vint_whole_mpdata_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     dse[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     p = 'mix_vint_whole_mpdata_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     dsm[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     p = 'mix_vint_top1m_mpdata_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     dsm_1m[i].to_netcdf(p, mode = 'w')\n",
    "\n",
    "# HSIMT\n",
    "# for i in range(len(paths)):\n",
    "#     # svar[i].attrs = ''\n",
    "#     # svar[i].name = 'svar'\n",
    "#     p = 'svar_vavg_whole_hsimt_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     svar[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     svar_1m[i].attrs = ''\n",
    "#     svar_1m[i].name = 'svar'\n",
    "#     p = 'svar_vavg_top1m_hsimt_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     svar_1m[i].to_netcdf(p, mode = 'w')\n",
    "\n",
    "# for i in range(len(paths)):\n",
    "#     p = 'ene_vint_whole_hsimt_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     dse[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     p = 'mix_vint_whole_hsimt_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     dsm[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     p = 'mix_vint_top1m_hsimt_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     dsm_1m[i].to_netcdf(p, mode = 'w')\n",
    "\n",
    "# # U3HC4\n",
    "for i in range(len(paths)):\n",
    "    # svar[i].attrs = ''\n",
    "    # svar[i].name = 'svar'\n",
    "    p = 'svar_vavg_whole_u3hc4_'+'ensemble_'+str(i+n)+'.nc'\n",
    "    svar[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     svar_1m[i].attrs = ''\n",
    "#     svar_1m[i].name = 'svar'\n",
    "#     p = 'svar_vavg_top1m_u3hc4_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     svar_1m[i].to_netcdf(p, mode = 'w')\n",
    "\n",
    "# for i in range(len(paths)):\n",
    "#     p = 'ene_vint_whole_u3hc4_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     dse[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     p = 'mix_vint_whole_u3hc4_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     dsm[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     p = 'mix_vint_top1m_u3hc4_'+'ensemble_'+str(i+n)+'.nc'\n",
    "#     dsm_1m[i].to_netcdf(p, mode = 'w') "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6937f85f-1161-466f-bbbe-42877a0cbf9b",
   "metadata": {},
   "source": [
    "### Code for the entire path list at once\n",
    "It is commented out as backup "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c40e712c-74f0-484c-ba4f-6337c3eae02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # HSIMT\n",
    "# for i in range(len(paths)):\n",
    "#     svar[i].attrs = ''\n",
    "#     svar[i].name = 'svar'\n",
    "#     p = 'svar_vavg_whole_hsimt_'+'ensemble_'+str(i)+'.nc'\n",
    "#     svar[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     svar_1m[i].attrs = ''\n",
    "#     svar_1m[i].name = 'svar'\n",
    "#     p = 'svar_vavg_top1m_hsimt_'+'ensemble_'+str(i)+'.nc'\n",
    "#     svar_1m[i].to_netcdf(p, mode = 'w')\n",
    "\n",
    "# for i in range(len(paths)):\n",
    "#     p = 'ene_vint_whole_hsimt_'+'ensemble_'+str(i)+'.nc'\n",
    "#     dse[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     p = 'mix_vint_whole_hsimt_'+'ensemble_'+str(i)+'.nc'\n",
    "#     dsm[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     p = 'mix_vint_top1m_hsimt_'+'ensemble_'+str(i)+'.nc'\n",
    "#     dsm_1m[i].to_netcdf(p, mode = 'w')\n",
    "\n",
    "# # MPDATA\n",
    "# for i in range(len(paths)):\n",
    "#     svar[i].attrs = ''\n",
    "#     svar[i].name = 'svar'\n",
    "#     p = 'svar_vavg_whole_mpdata_'+'ensemble_'+str(i)+'.nc'\n",
    "#     svar[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     svar_1m[i].attrs = ''\n",
    "#     svar_1m[i].name = 'svar'\n",
    "#     p = 'svar_vavg_top1m_mpdata_'+'ensemble_'+str(i)+'.nc'\n",
    "#     svar_1m[i].to_netcdf(p, mode = 'w')\n",
    "\n",
    "# for i in range(len(paths)):\n",
    "#     p = 'ene_vint_whole_mpdata_'+'ensemble_'+str(i)+'.nc'\n",
    "#     dse[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     p = 'mix_vint_whole_mpdata_'+'ensemble_'+str(i)+'.nc'\n",
    "#     dsm[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     p = 'mix_vint_top1m_mpdata_'+'ensemble_'+str(i)+'.nc'\n",
    "#     dsm_1m[i].to_netcdf(p, mode = 'w')\n",
    "\n",
    "# # U3HC4\n",
    "# for i in range(len(paths)):\n",
    "#     svar[i].attrs = ''\n",
    "#     svar[i].name = 'svar'\n",
    "#     p = 'svar_vavg_whole_u3hc4_'+'ensemble_'+str(i)+'.nc'\n",
    "#     svar[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     svar_1m[i].attrs = ''\n",
    "#     svar_1m[i].name = 'svar'\n",
    "#     p = 'svar_vavg_top1m_u3hc4_'+'ensemble_'+str(i)+'.nc'\n",
    "#     svar_1m[i].to_netcdf(p, mode = 'w')\n",
    "\n",
    "# for i in range(len(paths)):\n",
    "#     p = 'ene_vint_whole_u3hc4_'+'ensemble_'+str(i)+'.nc'\n",
    "#     dse[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     p = 'mix_vint_whole_u3hc4_'+'ensemble_'+str(i)+'.nc'\n",
    "#     dsm[i].to_netcdf(p, mode = 'w')\n",
    "    \n",
    "# for i in range(len(paths)):\n",
    "#     p = 'mix_vint_top1m_u3hc4_'+'ensemble_'+str(i)+'.nc'\n",
    "#     dsm_1m[i].to_netcdf(p, mode = 'w')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "copano",
   "language": "python",
   "name": "copano"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
